{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Sgd:\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def calculate_update(self, weight_tensor, gradient_tensor):\n",
    "        return weight_tensor - self.learning_rate*gradient_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.weights_prim_size = (self.input_size+1, self.output_size ) # +1 for bias\n",
    "        self.weight_prime = np.random.uniform(0,1,self.weights_prim_size) #Transposed whights matrix\n",
    "        self.optimizer = None #learning rate\n",
    "        \n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        input_tensor_prime = input_tensor\n",
    "        batch_size = input_tensor_prime.shape[0]\n",
    "        bias_factors = np.ones(batch_size) #np.ones(batch_size, dtype='int')\n",
    "        self.input_tensor_prime_w_bias_factors = np.concatenate((input_tensor_prime, bias_factors[:,None]),  axis=1) #transposed inputs with ones as factors for bias\n",
    "        \n",
    "        return np.dot(input_tensor_prime_w_bias_factors , self.weight_prime)\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def set_optimizer(self):\n",
    "        return self.optimizer\n",
    "    @set_optimizer.setter\n",
    "    def set_optimizer(self, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    \n",
    "    def backward(self, error_tensor):\n",
    "        error_tensor_prim = error_tensor\n",
    "        error_tensor_next = np.dot(error_tensor_prim, self.weight_prime.T)\n",
    "        self.grad_weight = np.dot(self.input_tensor_prime_w_bias_factors.T, error_tensor_prim)\n",
    "        \n",
    "        if self.optimizer != None:\n",
    "            self.weight_prime = self.optimizer.calculate_update(self.weight_prime, self.grad_weight)\n",
    "        \n",
    "        return error_tensor_next\n",
    "    \n",
    "        \n",
    "    @property\n",
    "    def gradient_weights(self):\n",
    "        return self.grad_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3, 12, 43],\n",
       "       [ 4,  5,  6, 12, 56],\n",
       "       [ 7,  8,  9, 12, 52]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.array([[1,2,3,12,43],[4,5,6,12,56],[7,8,9,12,52]])\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = np.ones(i.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3., 12., 43.],\n",
       "       [ 4.,  5.,  6., 12., 56.],\n",
       "       [ 7.,  8.,  9., 12., 52.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_1 = np.concatenate((i, o[:,None].T),  axis=0)\n",
    "i_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_1[i_1>10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 0., 0.],\n",
       "       [4., 5., 6., 0., 0.],\n",
       "       [7., 8., 9., 0., 0.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26123953, 0.22275566, 0.80440724, 0.75912603],\n",
       "       [0.26392119, 0.25424525, 0.75159542, 0.23682533],\n",
       "       [0.11307371, 0.92077259, 0.33970381, 0.6942968 ],\n",
       "       [0.28074939, 0.03582858, 0.46781135, 0.54248477]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.uniform(0,1,(4, i.shape[0]+1))\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.54223887,  8.8306413 , 10.11904374,  0.75912603,  0.75912603],\n",
       "       [ 6.77889542,  8.04865727,  9.31841913,  0.23682533,  0.23682533],\n",
       "       [ 6.8683875 ,  8.24193761,  9.61548771,  0.6942968 ,  0.6942968 ],\n",
       "       [ 4.24122796,  5.02561729,  5.81000662,  0.54248477,  0.54248477]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(w,i_1)[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., 12., 43.],\n",
       "       [ 0.,  0.,  0., 12., 56.],\n",
       "       [ 0.,  0.,  0., 12., 52.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(i_1 >= 10) * i_1 \n",
    "\n",
    "#(self.input_tensor >= 0) * error_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82071732, 0.02536475, 0.50364928, 0.67611402, 0.82753202,\n",
       "        0.49583446],\n",
       "       [0.3781678 , 0.11089174, 0.84139971, 0.88469295, 0.38271595,\n",
       "        0.17176547],\n",
       "       [0.99068403, 0.205514  , 0.96835957, 0.17656044, 0.03116604,\n",
       "        0.03869995]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay = 3\n",
    "in_siz = 5\n",
    "w_siz = (lay, in_siz+1)\n",
    "np.random.uniform(0,1,w_siz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3, 12, 43],\n",
       "       [ 4,  5,  6, 12, 56],\n",
       "       [ 7,  8,  9, 12, 52]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_prime = np.array([[1,2,3,12,43],[4,5,6,12,56],[7,8,9,12,52]])\n",
    "input_tensor_prime #three inputs each is size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = input_tensor_prime.shape[0]\n",
    "bias_factors = np.ones(batch_size) #np.ones(batch_size, dtype='int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3., 12., 43.,  1.],\n",
       "       [ 4.,  5.,  6., 12., 56.,  1.],\n",
       "       [ 7.,  8.,  9., 12., 52.,  1.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input_tensor_prime_w_bias_factors = \n",
    "np.concatenate((input_tensor_prime, bias_factors[:,None]),  axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "print(np.finfo(float).eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3., 12., 43.],\n",
       "       [ 4.,  5.,  6., 12., 56.],\n",
       "       [ 7.,  8.,  9., 12., 52.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-42., -41., -40., -31.,   0.],\n",
       "       [-52., -51., -50., -44.,   0.],\n",
       "       [-45., -44., -43., -40.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_1 - np.max(i_1, axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.72783947e+18],\n",
       "       [2.09165950e+24],\n",
       "       [3.83100800e+22],\n",
       "       [1.35914091e+01]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(i_1), axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(input_tensor + np.finfo(float).eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    " L = [0,10,20,40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 20, 10, 0]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
